from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, HumanMessage
from dotenv import load_dotenv
import os
load_dotenv()

# 1. LLM ì´ˆê¸°í™” 
llm = ChatGoogleGenerativeAI(
    model="models/gemini-2.0-flash",
    temperature=0.7,
    google_api_key=os.environ["GOOGLE_API_KEY"]  # ì—¬ê¸°ë¥¼ ëª…ì‹œí•´ì¤˜ì•¼ í•¨!
)

# 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”."),
    MessagesPlaceholder(variable_name="chat_history"), # ì´ì „ ëŒ€í™” ë‚´ìš©ì´ ë“¤ì–´ê°ˆ ìë¦¬
    ("human", "{user_input}"), # í˜„ì¬ ì‚¬ìš©ìì˜ ì…ë ¥ì´ ë“¤ì–´ê°ˆ ìë¦¬
])

# 3. LangChain ì²´ì¸ êµ¬ì„±
# í”„ë¡¬í”„íŠ¸ì™€ LLMì„ íŒŒì´í”„(|)ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
chain = prompt | llm

# âœ… 4. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜
def chat_node(state: dict) -> dict:
    """
    ì¼ë°˜ì ì¸ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ëŠ” Chat Node ì…ë‹ˆë‹¤.
    ëŒ€í™” ê¸°ë¡(chat_history)ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    user_input = state["user_input"]
    chat_history = state["chat_history"]

    # ì²´ì¸ì„ ì‹¤í–‰í•˜ì—¬ LLMìœ¼ë¡œë¶€í„° ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
    response = chain.invoke({
        "chat_history": chat_history,
        "user_input": user_input
    })

    # ìƒˆë¡œìš´ ëŒ€í™” ë‚´ìš©ì„ ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    # HumanMessageì™€ AIMessage ê°ì²´ë¡œ ì €ì¥í•´ì•¼ MessagesPlaceholderê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹í•©ë‹ˆë‹¤.
    updated_history = chat_history + [
        HumanMessage(content=user_input),
        AIMessage(content=response.content)
    ]

    # ì—…ë°ì´íŠ¸ëœ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return {
        "chat_history": updated_history,
        "last_response": response.content # ë¼ìš°í„°ë‚˜ UIì—ì„œ ë§ˆì§€ë§‰ ì‘ë‹µì„ ì‰½ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨
    }

# --- í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ ---
if __name__ == '__main__':
    print("ğŸ¤– Chat Node í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "user_input": "ì§€ê¸ˆ ì‹œê°„ì´ ëª‡ ì‹œì•¼?",
        "chat_history": []
    }

    # ì²« ë²ˆì§¸ ëŒ€í™”
    result1 = chat_node(initial_state)
    print("User:", initial_state["user_input"])
    print("AI:", result1["last_response"])

    print("\n--- ë‹¤ìŒ ëŒ€í™” ---")

    # ë‘ ë²ˆì§¸ ëŒ€í™” (ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ëŠ”ì§€ í™•ì¸)
    second_state = {
        "user_input": "ë‚´ê°€ ë°©ê¸ˆ ë­ë¼ê³  ë¬¼ì–´ë´¤ì§€?",
        "chat_history": result1["chat_history"] # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë„˜ê²¨ì¤Œ
    }

    result2 = chat_node(second_state)
    print("User:", second_state["user_input"])
    print("AI:", result2["last_response"])