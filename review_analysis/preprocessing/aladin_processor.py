# konlpy, pandas ë“± ì™¸ë¶€ íŒ¨í‚¤ì§€ ìžë™ì„¤ì¹˜
import sys
import subprocess

def install(package, import_name=None):
    try:
        __import__(import_name or package)
        print(f"âœ… {package} ì„¤ì¹˜ë˜ì–´ ìžˆìŒ")
    except ImportError:
        print(f"ðŸ“¦ {package} ì„¤ì¹˜ ì¤‘...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])

install("konlpy")
install("pandas")
install("scikit-learn", "sklearn")

# konlpy JDK ë¥¼ ìžë™ ë‹¤ìš´ë¡œë“œí•´ì£¼ì§€ ì•Šì§€ë§Œ, pipë¡œë§Œ ë˜ëŠ” ì„œë²„/Google Colab/Jupyterì—ì„  ë¬¸ì œì—†ì´ ì‚¬ìš© ê°€ëŠ¥

from sklearn.feature_extraction.text import TfidfVectorizer
from konlpy.tag import Okt
from abc import ABC, abstractmethod
import pandas as pd
import os
import re
from review_analysis.preprocessing.base_processor import BaseDataProcessor

class AladinProcessor(BaseDataProcessor):
    def __init__(self, input_path: str, output_path: str):
        super().__init__(input_path, output_path)
        self.df = None
        self.okt = Okt()

    def preprocess(self):

        print("ì•Œë¼ë”˜ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œìž‘")
        self.df = pd.read_csv(self.input_path)

        # ê²°ì¸¡ì¹˜, ì´ìƒì¹˜ ì²˜ë¦¬
        self.df.dropna(subset=['rating', 'review', 'date'], inplace=True)
        self.df['rating'] = pd.to_numeric(self.df['rating'], errors='coerce')
        self.df = self.df[(self.df['rating'] >= 1) & (self.df['rating'] <= 5)]
        self.df['date'] = pd.to_datetime(self.df['date'], errors='coerce')
        self.df.dropna(subset=['date'], inplace=True)
        self.df['review'] = self.df['review'].astype(str)
        self.df['clean_review'] = self.df['review'].str.replace(r'[^\x00-\x7F\uAC00-\uD7A3\w\s]', '', regex=True)

        # í•œê¸€ìžÂ·ì¡°ì‚¬ í¬í•¨ stopwords
        korean_stopwords = set([
            'ì´','ê·¸','ì €','ê²ƒ','ìˆ˜','ë“¤','ì¢€','ë”','ìž˜','ë§Žì´','ìžì£¼','ê°™ì´','ê±°ì˜','ë„ˆë¬´','ì •ë§','ê·¸ë¦¬ê³ ','ë˜í•œ',
            'í•˜ì§€ë§Œ','ê·¸ëŸ¬ë‚˜','ë•Œë¬¸ì—','ê·¸ëž˜ì„œ','ê±°ë‚˜','í•˜ë©°','í•˜ëŠ”','ì—ëŠ”','ã…Žã…Ž','ã…‹ã…‹','ã… ã… ','...','..','â€¦','ã…¡ã…¡','~~','--',
            'ê±°','ë‹¤','ê¹Œì§€','ì´ë‹¤','ìž…ë‹ˆë‹¤','ìžˆìŠµë‹ˆë‹¤','í•©ë‹ˆë‹¤','ì œ','ìš°ë¦¬','ê·¸ëƒ¥','ë˜','ë‹¤ì‹œ','ì¢€ë”','ê³„ì†','í•­ìƒ','ì‚¬ì‹¤','ë³´í†µ',
            'ëŒ€ë¶€ë¶„','í˜¹ì‹œ','ìš”ì¦˜','ë”ìš±','ì˜','ê°€','ì´','ì€','ëŠ”','ì„','ë¥¼','ì—','ë„','ì™€','í•œ','ê³¼','ë¡œ','ì—ì„œ','ì˜','ê³¼','ë„','ë¥¼','ë¡œì„œ',
            'ë¡œì¨','ì—ì„œ','ê¹Œì§€','ì—ê²Œ','ê»˜ì„œ','ë§Œ','ë°–ì—','ë³´ë‹¤','ì²˜ëŸ¼','ë³´ë‹¤','ê¹Œì§€','ì´ë©°','í•˜ë©´ì„œ','ìœ¼ë¡œ','ì—ê²Œë¡œ','ì˜€ë‹¤','í–ˆë‹¤','ëë‹¤','ì´ë‹¤',
            'í•˜ê²Œ','í•˜ê²Œë”','í•˜ê²Œë‚˜','í•˜ê¸°','í•´ì„œ','í–ˆë”ë‹ˆ','í•´ì„œëŠ”','í•˜ê³ ','í•˜ë©°','í•˜ê³ ì„œë„'
        ])

        def clean_and_tokenize(text):
            tokens = self.okt.morphs(text)
            filtered = [t for t in tokens if t not in korean_stopwords]
            return ' '.join(filtered)
        
        self.df['clean_review'] = self.df['clean_review'].apply(clean_and_tokenize)
        self.df = self.df[self.df['clean_review'].str.len() > 10]
        self.df = self.df[self.df['clean_review'].str.len() < 100]
        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.df)} rows")

    def feature_engineering(self):
        self.df['year_month'] = self.df['date'].dt.to_period('M').astype(str)
        vectorizer = TfidfVectorizer(max_features=100)
        tfidf_matrix = vectorizer.fit_transform(self.df['clean_review'])
        print("âœ… feature engineering ì™„ë£Œ / TF-IDF shape:", tfidf_matrix.shape)

    def save_to_database(self):
        self.df = self.df[['review', 'clean_review', 'rating', 'date', 'year_month']]
        os.makedirs(self.output_dir, exist_ok=True)
        save_path = os.path.join(self.output_dir, 'preprocessed_reviews_aladin.csv')
        self.df.to_csv(save_path, index=False)
        print("âœ… ì €ìž¥ ì™„ë£Œ â†’", save_path)